---
title: "train summary 0515"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

학습데이터 : 1973~2012 (40개) , 시험데이터 : 2013~2018 (6개)

lambda = (0, 0.1, 0.2, ..., 0.9, 1)
```{r, echo=FALSE, message=FALSE}
rm( list = ls()); gc()
setwd("C:\\Users\\UOS\\Documents\\GITHUB\\gev")
source("sgevlibrary.R")
load("kma_data\\Pr_46.Rdata")
library(fda)
library(dplyr)

# 1973~2012 for train, 2013~2018 for test
train = Pr_46 %>% filter(obsyear < 2013)
test = Pr_46 %>% filter(obsyear >= 2013)
ns = length(unique(Pr_46$stnlds)) # 56개

ss = split.data.frame(train,train$stnlds)
xlist = lapply(ss,"[[","pr")
x_bsobj = create.bspline.basis(range(train$long),breaks=quantile(train$long,prob = seq(0, 1, length = 3)))
y_bsobj = create.bspline.basis(range(train$lat),breaks=quantile(train$lat,prob = seq(0, 1, length = 3)))

zlist = list()
for (i in 1:ns){
  xbs = eval.basis(ss[[i]]$long,x_bsobj)
  ybs = eval.basis(ss[[i]]$lat,y_bsobj)
  tensorbs = do.call('cbind', lapply(1:ncol(xbs), function(i) xbs[, i] * ybs)) 
  zlist[[i]] = tensorbs 
}

# Omega matrix
Fmat = kronecker(bsplinepen(x_bsobj,Lfdobj=2),bsplinepen(y_bsobj,Lfdobj=0))
Gmat = kronecker(bsplinepen(x_bsobj,Lfdobj=0),bsplinepen(y_bsobj,Lfdobj=2))
Hmat = kronecker(bsplinepen(x_bsobj,Lfdobj=1),bsplinepen(y_bsobj,Lfdobj=1))
Om = Fmat+2*Gmat+Hmat

# design matrix for v3 (m0 statinary?)
matfunc = function(ns){
  matt = matrix(0,nrow=ns*(ns-1),ncol=ns)
  k = 1
  for (i in (1: (ns-1))){
    for (j in ((i+1) :ns)){
      matt[k,i] = 1
      matt[k,j] = -1
      k = k+1
    }  
  }
  mat = t(matt) %*% matt
  return(mat)
}
mat = matfunc(ns)

# optim control
optim_controlList = list()
optim_controlList$maxit = 1e+3

# lambdaset
lambdaset = seq(0,1,length=11)

# loss
lossfun = function(x,mu,s,k){
  v = log(s)+(1+1/k)*log(1+k*(x-mu)/s)+(1+k*(x-mu)/s)^(-1/k)  
  sum(v)
}

```


## 연도순으로 5 folds 나누어 적합

예) validation set for 1 folds : 1973~1980 (8개) train set for 1 folds : 1981~2012 (32개)
```{r}
load("C:\\Users\\UOS\\Documents\\GITHUB\\gev\\kfolds=5sequential_knots=4.RData")
```

NaN 제외하고 평균내서 lambda 최솟값 찾기 - 0.0
```{r, echo=FALSE}
# lambda1 min 찾기 
validation.mat <- do.call('rbind',result_validation);validation.mat
lambda.min <- lambdaset[which.min(colMeans(validation.mat,na.rm=TRUE))]
par(mfrow=c(1,1))
plot(lambdaset,colMeans(validation.mat,na.rm=TRUE))
abline(v=lambda.min,lty=2)
```

test 적합 likelihood 
```{r, echo=FALSE}
# 최종 적합 - train set
test_est <- gevreg_m(xlist,zlist,lambda = lambda.min , lambda2=1, Om=Om, mat=mat, method="B-spline")

# test likelihood
test_ss = split.data.frame(test,test$stnlds)
test_xlist = lapply(test_ss,"[[","pr")

v=c()
est_z = tail(test_est,25) 
for (s in 1:ns){
  est_s = test_est[(1:3)+(3*s-3)]
  v[s] = lossfun(test_xlist[[s]],mu=c(est_s[1]+zlist[[s]][1,]%*%est_z),s=est_s[2],k=est_s[3])
}
result_test <- sum(v)
print(result_test)
```



## 랜덤하게 5 folds 나누어 적합 (case1)


```{r}
load("C:\\Users\\UOS\\Documents\\GITHUB\\gev\\kfolds=random517_knots=3.RData")
```
NaN 제외하고 평균내서 lambda 최솟값 찾기 - 0.1
```{r, echo=FALSE}
# lambda1 min 찾기 
validation.mat <- do.call('rbind',result_validation);validation.mat
lambda.min <- lambdaset[which.min(colMeans(validation.mat,na.rm=TRUE))]
par(mfrow=c(1,1))
plot(lambdaset,colMeans(validation.mat,na.rm=TRUE))
abline(v=lambda.min,lty=2)
```
```{r, echo=FALSE}
# 최종 적합 - train set
test_est <- gevreg_m(xlist,zlist,lambda = lambda.min , lambda2=1, Om=Om, mat=mat, method="B-spline")

# test likelihood
test_ss = split.data.frame(test,test$stnlds)
test_xlist = lapply(test_ss,"[[","pr")

v=c()
est_z = tail(test_est,25) 
for (s in 1:ns){
  est_s = test_est[(1:3)+(3*s-3)]
  v[s] = lossfun(test_xlist[[s]],mu=c(est_s[1]+zlist[[s]][1,]%*%est_z),s=est_s[2],k=est_s[3])
}
result_test <- sum(v)
print(result_test)
```



```{r}
load("C:\\Users\\UOS\\Documents\\GITHUB\\gev\\kfolds=random827_knots=3.RData")
```
NaN 제외하고 평균내서 lambda 최솟값 찾기 - 0.9
```{r, echo=FALSE}
# lambda1 min 찾기 
validation.mat <- do.call('rbind',result_validation);validation.mat
lambda.min <- lambdaset[which.min(colMeans(validation.mat,na.rm=TRUE))]
par(mfrow=c(1,1))
plot(lambdaset,colMeans(validation.mat,na.rm=TRUE))
abline(v=lambda.min,lty=2)
```
```{r, echo=FALSE}
# 최종 적합 - train set
test_est <- gevreg_m(xlist,zlist,lambda = lambda.min , lambda2=1, Om=Om, mat=mat, method="B-spline")

# test likelihood
test_ss = split.data.frame(test,test$stnlds)
test_xlist = lapply(test_ss,"[[","pr")

v=c()
est_z = tail(test_est,25) 
for (s in 1:ns){
  est_s = test_est[(1:3)+(3*s-3)]
  v[s] = lossfun(test_xlist[[s]],mu=c(est_s[1]+zlist[[s]][1,]%*%est_z),s=est_s[2],k=est_s[3])
}
result_test <- sum(v)
print(result_test)
```

NaN 제외하고 평균내서 lambda 최솟값 찾기 - 0.4
```{r}
load("C:\\Users\\UOS\\Documents\\GITHUB\\gev\\kfolds=random2018_knots=3.RData")
```
```{r, echo=FALSE}
# lambda1 min 찾기 
validation.mat <- do.call('rbind',result_validation);validation.mat
lambda.min <- lambdaset[which.min(colMeans(validation.mat,na.rm=TRUE))]
par(mfrow=c(1,1))
plot(lambdaset,colMeans(validation.mat,na.rm=TRUE))
abline(v=lambda.min,lty=2)
```

test set에서 계산 안됨
```{r, echo=FALSE}
# 최종 적합 - train set
test_est <- gevreg_m(xlist,zlist,lambda = lambda.min , lambda2=1, Om=Om, mat=mat, method="B-spline")

# test likelihood
test_ss = split.data.frame(test,test$stnlds)
test_xlist = lapply(test_ss,"[[","pr")

v=c()
est_z = tail(test_est,25) 
for (s in 1:ns){
  est_s = test_est[(1:3)+(3*s-3)]
  v[s] = lossfun(test_xlist[[s]],mu=c(est_s[1]+zlist[[s]][1,]%*%est_z),s=est_s[2],k=est_s[3])
}
result_test <- sum(v)
print(result_test)
```